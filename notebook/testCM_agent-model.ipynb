{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Individual Attri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Set working directory\"\n",
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_cm\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from math import exp, log\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "from agentpy_cm.objects import Object\n",
    "from agentpy_cm.agent import Agent\n",
    "#from agentpy_cm.sequences import AgentList_____________Remove\n",
    "#from agentpy_cm.tools import AgentpyError, make_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agentpy_cm.hypothesis import PARAMS_INDIVIDUAL, \\\n",
    "    PARAMS_IPF_WEIGHTS, Hypothesis\n",
    "from datetime import datetime\n",
    "from agentpy_cm.datadict import DataDict\n",
    "from agentpy_cm.sample import Range, Values\n",
    "from agentpy_cm.grid import Grid\n",
    "from agentpy_cm.space import Space\n",
    "from agentpy_cm.tools import AttrDict, AgentpyError, make_list, InfoStr\n",
    "from agentpy_cm.sequences import AgentList\n",
    "from agentpy_cm.model import Model\n",
    "# from .agent_cm import Individual, Populating ____________for SocPD file\n",
    "#from agentpy_cm.model_cm import SocPD # ____________only for runing final notwbook\n",
    "\n",
    "\n",
    "#comma\n",
    "\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Individual(Agent):\n",
    "\n",
    "    def setup(self):\n",
    "        # linking with model #--> Agent\n",
    "        \n",
    "        self.random = self.model.random\n",
    "        self.status_quo = self.model.status_quo\n",
    "        #self.Hypothesis_settings = self.p.Hypothesis_settings #______________removed\n",
    "        \n",
    "        #Grid method\n",
    "        self.grid = self.model.grid\n",
    "        \n",
    "        #local variable\n",
    "        #self.Hypothesis_settings = None #______________removed\n",
    "        self.status= False\n",
    "        self.moving= False\n",
    "        self.features = None\n",
    "        self.influencing_profile : pd.DataFrame\n",
    "        self.influenced_score :  pd.Series\n",
    "        self.move_to_pos : Tuple(int,int)\n",
    "        self.share_similar_diet :float = .0\n",
    "    \n",
    "        #Hypo_dict = self.p.Hypothesis_settings #_____________ removed\n",
    "        #Hypothesis.read_hypotheses(Hypo_dict)#__________________ removed\n",
    "\n",
    "        #call-out hypothesis on actions #__________________changed to model.....\n",
    "\n",
    "        self.env_beta = self.model.env_beta\n",
    "        self.actions = self.model.all_possible_actions\n",
    "        self.status_var = self.model.status_var\n",
    "        self.pos_nw_actions = self.model.pos_nw_actions \n",
    "        self.neg_nw_actions = self.model.neg_nw_actions       \n",
    "        self.decisions_to_move = self.model.decisions_to_move \n",
    "        self.decisions_to_adopt = self.model.decisions_to_adopt\n",
    "        self.actions_to_nw = self.model.actions_to_nw  \n",
    "        self.actions_to_self = self.model.actions_to_self\n",
    "        self.rules = self.model.data_dfs\n",
    "\n",
    "        \n",
    "        # parameters for populating\n",
    "        #self._pop : int = None ---> attach with model\n",
    "        #self._dir_params = self.p.dir_params\n",
    "\n",
    "        # get nw-influencin actions that decides moving from hypothesis\n",
    "        self.nw_decisions_to_move = list(set(self.decisions_to_move).intersection(set(self.actions_to_nw)))\n",
    "        self.self_decisions_to_move = list(set(self.decisions_to_move).intersection(set(self.actions_to_self)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_p(sum_betas:float) -> float:\n",
    "        '''logit reversed'''\n",
    "        return exp(sum_betas)/(1+exp(sum_betas))\n",
    "    \n",
    "    '''step 1 :set up agents's status'''\n",
    "    #TESTED \n",
    "    def get_status_step0(self) -> None: \n",
    "\n",
    "        fs = self.features\n",
    "        self.status = fs[f'{self.status_var}_yes'] ==1 \n",
    "\n",
    "    #TESTED\n",
    "    def scoring_influenced_self(self) ->pd.Series: \n",
    "        '''collect influenced score from self '''\n",
    "        params_self = self.rules['actions_to_self']\n",
    "        #actions = params_self.index___________REMOVE_________\n",
    "        _score_self = params_self.dot(self.features) \n",
    "        return _score_self #_______________EDIT_______\n",
    "    #TESTED\n",
    "    def set_influencing_profile(self) -> pd.DataFrame:\n",
    "        \n",
    "        params_nw = self.rules['actions_to_nw']\n",
    "        features = self.features  \n",
    "        #ncols = features.shape[0] _____________REMOVE_______\n",
    "\n",
    "        # Patching to get diagonal mtx of agent's features \n",
    "        #patched_profl = np.zeros((ncols, ncols))___________REMOVE_________\n",
    "        #patched_profl = np.fill_diagonal(patched_profl, np.array(features).flatten())__________REMOVE_____\n",
    "        # match action params to get agent's influenxing profile\n",
    "        influencing_profile = params_nw.mul(features)\n",
    "         \n",
    "        # zero-out the influence doesn't match agent's status\n",
    "        if self.status:\n",
    "            influencing_profile.loc[self.neg_nw_actions] = 0\n",
    "        else:\n",
    "            influencing_profile.loc[self.pos_nw_actions] = 0\n",
    "\n",
    "        #_________changed\n",
    "        self.influencing_profile = influencing_profile\n",
    "        \n",
    "    \n",
    "    # Update adoption status based on score\n",
    "    def update_status(self) -> bool: #_______________changed\n",
    "        _score = sum(self.influenced_score[self.decisions_to_adopt])\n",
    "        _score += self.env_beta + self.status_quo\n",
    "        return self.random.random() <= self.get_p(_score)\n",
    "    #_____________NOTE_______: changing enviromental beta\n",
    "    def update_agent_combined(self):\n",
    "        #-----------------------\n",
    "        # Testing individual computation in comma-main/../demo_individual\n",
    "        _score_self = self.scoring_influenced_self()\n",
    "        \n",
    "        ########## 2. Get scores of network-influenced ---- HOMOPHILY\n",
    "            ## UPDATE self influencing-profile, preparing to influence neighbor\n",
    "        # _______________removed_________________self.influencing_profile = self.set_influencing_profile()   \n",
    "        # if influencing profile need to be update the first time at global level to make sure neighbors have influencing'sprofile updated at step 0 \n",
    "            \n",
    "            ## Get network influenced scores from neighbor's influencing-profiles\n",
    "        neighbors = self.grid.neighbors(self)\n",
    "        if len(neighbors)>0:\n",
    "            neigh_prfs = [n.influencing_profile for n in neighbors]\n",
    "            \n",
    "                ## WARNING :Method HOMOPHILY - \n",
    "            result_nw = [p.dot(self.features) for p in neigh_prfs] #_________________changed \n",
    "\n",
    "            ### Method get lowest score in _score_to_move to defind weakest-tie neighbors\n",
    "                ### filter to get decision to move from network's influences, then sum score by neighbor\n",
    "                ### then get sum score from both self and nw decisions\n",
    "            #mask = np.isin(self.actions_to_nw, self.nw_decisions_to_move)_____________removed\n",
    "\n",
    "            #@TESTED________\n",
    "            #______________________changed \n",
    "            _score_to_move =[sum(s[self.nw_decisions_to_move]) \\\n",
    "                            + sum(_score_self[self.self_decisions_to_move]) \\\n",
    "                                for s in result_nw] \n",
    "                ### Access neighbor with weakest ties\n",
    "            \n",
    "            ### Decision to move away from lowest score neighbor - simple method: run random\n",
    "            \n",
    "            # TESTED_____\n",
    "            neigh_pos : Tuple(int,int) =  None\n",
    "            for i, nb in enumerate(neighbors):\n",
    "                if i == np.argmin(_score_to_move):\n",
    "                    neigh_pos = self.grid.positions[nb]\n",
    "                    choice = [2,-2]\n",
    "                    path = (self.random.choice(choice), self.random.choice(choice))\n",
    "                    self.move_to_pos = tuple([p + c for p, c in zip(path, neigh_pos)])\n",
    "                break\n",
    "            #____________changed\n",
    "            prob_move = self.get_p(-np.min(_score_to_move)) # reversed affect \n",
    "        else:\n",
    "            result_nw = [pd.Series(0, index = self.actions_to_nw)]\n",
    "            prob_move = self.get_p(-sum(_score_self[self.self_decisions_to_move]))\n",
    "            self.move_to_pos = self.random.choice(self.model.grid.empty)\n",
    "            \n",
    "\n",
    "        self.moving = self.random.random() <= prob_move\n",
    "\n",
    "        ### summary all action score of each agent\n",
    "        _score_nw = pd.Series(sum(result_nw))\n",
    "        \n",
    "        self.influenced_score = pd.concat([_score_self,_score_nw])\n",
    "        self.status = self.update_status()\n",
    "        \n",
    "        # For get_segregation\n",
    "        similar = len([n for n in neighbors if n.status == self.status])\n",
    "        ln = len(neighbors)\n",
    "        self.share_similar_diet = similar / ln if ln > 0 else 0\n",
    "   \n",
    "    '''STEP 4 : taking action following status'''\n",
    "    def find_new_friends(self):\n",
    "        self.grid.move_to(self, self.move_to_pos)\n",
    "        \n",
    "    def update_agent_profile_by_status(self): #_______________changed\n",
    "        if self.status:\n",
    "            self.features[self.features.index.str.contains(pat = f'{self.status_var}')] = [0,1]\n",
    "        else:\n",
    "            self.features[self.features.index.str.contains(pat = f'{self.status_var}')] = [1,0]    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Populating(Object):\n",
    "    def __init__(self, model):\n",
    "        super().__init__(model)\n",
    "        self.nprandom = model.nprandom \n",
    "        self.all_possible_features = self.model.all_possible_features#__________________change this\n",
    "        #self.dir_params = Hypothesis.dir_params #_________________removed\n",
    "    \n",
    "    def sampling_from_ipf(self, dir_params, pop:int) -> pd.DataFrame: #_____________changed\n",
    "        \"\"\"\n",
    "        Sample from IPF distribution saved\n",
    "        as `weights.csv` in the parameters folder\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        pop (int): size of data sample\n",
    "        dir_params (str): path to the parameters folder\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sample (pandas.dataFrame): dataframe containing the sampling\n",
    "        \"\"\"\n",
    "        fpath_weights = os.path.join(dir_params, PARAMS_IPF_WEIGHTS)#____________changed\n",
    "        assert os.path.isfile(fpath_weights)\n",
    "        df_weights = pd.read_csv(fpath_weights, sep=\",\", index_col=0)\n",
    "        weights = df_weights[\"weight\"] / df_weights[\"weight\"].sum()\n",
    "        indices = df_weights.index\n",
    "        \n",
    "        #______apply seed on numpy -> change np.random_____________________\n",
    "        sample_indices = self.nprandom.choice(indices, pop, p=weights) \n",
    "        sample = df_weights.loc[sample_indices].drop([\"weight\"], axis=1)\n",
    "        sample = sample.reset_index(drop=True)\n",
    "        return sample\n",
    "\n",
    "    def populate_ipf(self, dir_params, pop:int) -> List:  #_______________changed \n",
    "        \"\"\"\n",
    "        Create a population of individual agents\n",
    "        with the given weights obtained via IPF\n",
    "\n",
    "        Args:\n",
    "            pop (int): size of data sample.\n",
    "            dir_params (str): path to parameters folder.\n",
    "\n",
    "        Returns:\n",
    "            List[Individual]: A list containing instances of\n",
    "            the individual class, each representing an\n",
    "            agent with specific features.\n",
    "        \"\"\"\n",
    "        _features = pd.DataFrame()\n",
    "\n",
    "        sample = self.sampling_from_ipf(dir_params, pop)#_______________added\n",
    "\n",
    "        # one-hot encoding\n",
    "        encoded_columns = pd.get_dummies(sample).reindex(\n",
    "            columns=self.all_possible_features,\n",
    "            fill_value=0\n",
    "        )\n",
    "        _features = pd.concat([_features, encoded_columns], axis=1)\n",
    "        #________________added\n",
    "        cols = sorted(_features.columns)\n",
    "        _features = _features[cols]\n",
    "\n",
    "        # Add 'baseline' column filled with ones if this is not present yet\n",
    "        if 'baseline' not in _features.columns:\n",
    "            _features.insert(0, \"baseline\", 1)\n",
    "\n",
    "        return [_features.iloc[i] for i in\n",
    "                tqdm(range(pop), desc=\"Populating individuals\", unit=\"i\")]\n",
    "\n",
    "    def populate_simple(self, dir_params, pop:int) -> List:\n",
    "        \"\"\"\n",
    "        Create a population of individual agents\n",
    "        with the given feature parameters.\n",
    "\n",
    "        Args:\n",
    "            pop (int): population size, i.e., number of agents.\n",
    "            dir_params (str): dir to the folder containing\n",
    "            feature parameter file.\n",
    "            #from_scratch (bool, optional): flag of creating hypothesis\n",
    "            from scratch or reading from files. Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            list[Individual]: a list of Individual agents\n",
    "        \"\"\"\n",
    "        assert pop > 0, 'Size must be positive!'\n",
    "        assert isinstance(pop, int), 'Pop - population size must be integer!'\n",
    "        assert os.path.isdir(dir_params), \"Given folder doesn't exist!\"\n",
    "        #_________________changed\n",
    "        fpath_params_individual = os.path.join(dir_params, PARAMS_INDIVIDUAL) #_______________changed\n",
    "        with open(fpath_params_individual) as f:\n",
    "            features = json.load(f)\n",
    "\n",
    "        _features = pd.DataFrame()\n",
    "        for feature, distribution in features.items():\n",
    "            _features[feature] = self.nprandom.choice(\n",
    "                distribution[0], pop, p=distribution[1]\n",
    "            )\n",
    "\n",
    "            # Define all possible columns (including those not in the sample)\n",
    "            # When the sample size is too small,\n",
    "            # this doesn't cover all categories,\n",
    "            # the resulting DataFrame thus lacks those columns.\n",
    "            # To solve the issue, we ensure all possible categories are present\n",
    "            # when creating the dummy variables\n",
    "\n",
    "        # one-hot encoding\n",
    "        categorical_cols = _features.select_dtypes(include=['object'])\n",
    "        encoded_cols = pd.get_dummies(categorical_cols).reindex(\n",
    "            columns=self.all_possible_features,\n",
    "            fill_value=0\n",
    "        )\n",
    "        _features.drop(categorical_cols.columns, axis=1, inplace=True)\n",
    "        _features = pd.concat([_features, encoded_cols], axis=1)\n",
    "         #________________added\n",
    "        cols = sorted(_features.columns)\n",
    "        _features = _features[cols]\n",
    "\n",
    "        # Add 'baseline' column filled with ones\n",
    "        _features.insert(0, \"baseline\", 1)\n",
    "\n",
    "        return [_features.iloc[i] for i in\n",
    "                tqdm(range(pop), desc=\"Populating individuals\", unit=\"i\")]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SocPD(Model, Hypothesis):  \n",
    "    def setup(self) :\n",
    "                # Private variables\n",
    "\n",
    "        # Set-up Hypothesis \n",
    "        Hypo_dict = self.p.Hypothesis_settings #_____________ added\n",
    "        Hypothesis.validate_n_read_hypotheses(Hypo_dict)#__________________added\n",
    "\n",
    "        #call-out hypothesis on actions\n",
    "        self._dir_params = Hypothesis.dir_params\n",
    "        self.env_beta = Hypothesis.env_beta\n",
    "        self.actions = Hypothesis.all_possible_actions\n",
    "        self.status_var = Hypothesis.status_var\n",
    "        self.pos_nw_actions = Hypothesis.pos_nw_actions \n",
    "        self.neg_nw_actions = Hypothesis.neg_nw_actions       \n",
    "        self.decisions_to_move = Hypothesis.decisions_to_move \n",
    "        self.decisions_to_adopt = Hypothesis.decisions_to_adopt\n",
    "        self.actions_to_nw = Hypothesis.actions_to_nw  \n",
    "        self.actions_to_self = Hypothesis.actions_to_self\n",
    "        self.rules = Hypothesis.data_dfs\n",
    "\n",
    "        # Set up simple model's params\n",
    "        self.status_quo = 0\n",
    "        self._use_ipf : None = bool\n",
    "        pop = self.pop = self.p['pop']\n",
    "        den = self.p['den']\n",
    "        s = int(np.ceil(np.sqrt(pop/den)))\n",
    "\n",
    "        if 'use_ipf' in self.p:\n",
    "            self._use_ipf = self.p['use_ipf']\n",
    "        else:\n",
    "            self._use_ipf = False  #_____________ changed\n",
    "        self.report('use_ipf', self._use_ipf) #___________changed\n",
    "        #self.Hypothesis_settings = self.p.Hypothesis_settings\n",
    "        \n",
    "        #____________GRID_______________________________\n",
    "        # setup model's Grid\n",
    "        self.grid = Grid(self, (s, s), track_empty=True)\n",
    "        #____________AGENTS________________________________\n",
    "        # generate agents\n",
    "        self.agents = AgentList(self, pop, Individual) \n",
    "        # generate features then update agent's features and status\n",
    "        self.Populating = Populating(self)\n",
    "        if self._use_ipf: #___________ changed\n",
    "            _feature_iter = self.Populating.populate_ipf(self._dir_params, pop)\n",
    "        else:\n",
    "            _feature_iter = self.Populating.populate_simple(self._dir_params, pop)        \n",
    "            # update agent's features \n",
    "        for i, a in enumerate(self.agents):\n",
    "            a.features = _feature_iter[i]\n",
    "            # update Agent status based on feature generation        \n",
    "        self.agents.get_status_step0()\n",
    "        #____________ADD AGENTS ON THE GRID_______________\n",
    "        self.grid.add_agents(self.agents, random=True, empty=True)\n",
    "\n",
    "\n",
    "    def update(self): \n",
    "        ''' TESTING updated status and profile\n",
    "        for i, a in enumerate(self.agents):\n",
    "            if i ==4:\n",
    "                print(f'step: {self.t}')\n",
    "                print(f'current status : {a.status}')\n",
    "        '''\n",
    "        positive_agents = self.agents.select(self.agents.status==True)\n",
    "        self.status_quo = len(positive_agents)/self.pop\n",
    "\n",
    "        # Stop simulation if all are positive or negative\n",
    "        if self.status_quo == 0 or self.status_quo == 1:\n",
    "            self.stop()\n",
    "        #record status\n",
    "        self['positive'] = self.status_quo\n",
    "        self.record('positive')\n",
    "        self['negative'] = 1 - self['positive']\n",
    "        self.record('negative')\n",
    "        \n",
    "        # update from t= 0\n",
    "        self.agents.set_influencing_profile()  #___________ADDED\n",
    "        self.agents.update_agent_combined()\n",
    "        self.unhappy = self.agents.select(self.agents.moving == True)\n",
    "        ''' TESTING updated status and profile\n",
    "        for i, a in enumerate(self.agents):\n",
    "            if i ==4:\n",
    "                print('current profile')\n",
    "                print(a.features[a.features.index.str.contains(pat = f'{self.status_var}')])\n",
    "                print(f'updated status : {a.status}')\n",
    "\n",
    "                print()\n",
    "        '''\n",
    "            \n",
    "\n",
    "    def step(self):\n",
    "        self.unhappy.find_new_friends()\n",
    "        self.agents.update_agent_profile_by_status()\n",
    "    \n",
    "    def get_segregation(self):\n",
    "        # Calculate average percentage of similar neighbors\n",
    "        return round(sum(self.agents.share_similar_diet) / self.pop, 2)\n",
    "\n",
    "    def end(self):\n",
    "        # Measure segregation at the end of the simulation\n",
    "        self.report('segregation', self.get_segregation())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_params = 'parameters_demo'\n",
    "all_possible_actions=  ['veg_prob', \n",
    "                        'influencing_Veg', \n",
    "                        'influencing_Om', \n",
    "                        'nw_satisfaction', \n",
    "                        'making_effort', \n",
    "                        'environment_veg']\n",
    "\n",
    "Hypothesis_settings = { 'dir_params' : dir_params ,\n",
    "                        'status_var':'Depressed',\n",
    "                        'all_possible_actions':all_possible_actions,\n",
    "                        'actions_to_self':['veg_prob', 'nw_satisfaction','environment_veg'],\n",
    "                        'actions_to_nw':['influencing_Veg', 'influencing_Om','making_effort'],\n",
    "                        'pos_nw_actions':['influencing_Veg'],\n",
    "                        'neg_nw_actions':['influencing_Om'],\n",
    "                        'decisions_to_move':['nw_satisfaction', 'making_effort',  ],\n",
    "                        'decisions_to_adopt':['veg_prob', 'influencing_Veg', 'influencing_Om', 'environment_veg'], \n",
    "                        'env_beta': -0.8}\n",
    "\n",
    "\n",
    "parameters = {'Hypothesis_settings' : Hypothesis_settings,\n",
    "            'pop' : 15,\n",
    "            'den': .75,\n",
    "            'steps': 10,\n",
    "            'seed' : 234,\n",
    "            'use_ipf': True,\n",
    "            } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Populating individuals: 100%|██████████| 15/15 [00:00<00:00, 14898.07i/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0\n",
      "current status : False\n",
      "current profile\n",
      "depressed_no     1\n",
      "depressed_yes    0\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "step: 1\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 1 stepsstep: 2\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 2 stepsstep: 3\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : False\n",
      "\n",
      "Completed: 3 stepsstep: 4\n",
      "current status : False\n",
      "current profile\n",
      "depressed_no     1\n",
      "depressed_yes    0\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 4 stepsstep: 5\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 5 stepsstep: 6\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 6 stepsstep: 7\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : False\n",
      "\n",
      "Completed: 7 stepsstep: 8\n",
      "current status : False\n",
      "current profile\n",
      "depressed_no     1\n",
      "depressed_yes    0\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 8 stepsstep: 9\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 9 stepsstep: 10\n",
      "current status : True\n",
      "current profile\n",
      "depressed_no     0\n",
      "depressed_yes    1\n",
      "Name: 4, dtype: int64\n",
      "updated status : True\n",
      "\n",
      "Completed: 10 steps\n",
      "Run time: 0:00:00.797336\n",
      "Simulation finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataDict {\n",
       "'info': Dictionary with 9 keys\n",
       "'parameters': \n",
       "    'constants': Dictionary with 6 keys\n",
       "'variables': \n",
       "    'SocPD': DataFrame with 2 variables and 11 rows\n",
       "'reporters': DataFrame with 3 variables and 1 row\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = SocPD(parameters)\n",
    "model.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42, 'use_ipf': True, 'segregation': 0.51}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.reporters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animation_plot(model, ax):\n",
    "    group_grid = model.grid.attr_grid('group')\n",
    "    ap.gridplot(group_grid, cmap='Accent', ax=ax)\n",
    "    ax.set_title(f\"Segregation model \\n Time-step: {model.t}, \"\n",
    "                 f\"Segregation: {model.get_segregation()}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "model = SegregationModel(parameters)\n",
    "animation = ap.animate(model, fig, ax, animation_plot)\n",
    "IPython.display.HTML(animation.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
